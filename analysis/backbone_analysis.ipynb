{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pprint\n",
    "from tensorboardX import SummaryWriter\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numpy.linalg import svd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sys.path = ['..'] + sys.path\n",
    "from algorithm_trainer.models import gated_conv_net_original, resnet, resnet_2, resnet_12, conv64\n",
    "from algorithm_trainer.algorithm_trainer import Generic_adaptation_trainer, Classical_algorithm_trainer\n",
    "from algorithm_trainer.algorithms.algorithm import SVM, ProtoNet, Finetune\n",
    "from algorithm_trainer.utils import accuracy\n",
    "from data_layer.dataset_managers import MetaDataManager, ClassicalDataManager\n",
    "from analysis.objectives import var_reduction_disc, var_reduction_disc_perp, var_reduction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, checkpoint):\n",
    "    print(f\"loading from {checkpoint}\")\n",
    "    model_dict = model.state_dict()\n",
    "    chkpt_state_dict = torch.load(checkpoint)\n",
    "    if 'model' in chkpt_state_dict:\n",
    "        chkpt_state_dict = chkpt_state_dict['model']\n",
    "    chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "    # remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "    for key in chkpt_state_dict_cpy.keys():\n",
    "        if 'module.' in key:\n",
    "            new_key = re.sub('module\\.', '',  key)\n",
    "            chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "    chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "    model_dict.update(chkpt_state_dict)\n",
    "    updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "    missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "    print(f\"Missed {len(missed_keys)} keys\")\n",
    "    model.load_state_dict(model_dict)\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "    model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 84\n",
    "batch_size = 2\n",
    "n_way = 5\n",
    "n_shot = 1\n",
    "n_query = 15\n",
    "n_episodes = 400\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "chkpt = '../train_dir/metal_MI_r12_n60_s5_q5_euc/classical_resnet_015.pt'\n",
    "model = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model = load_model(model, chkpt)\n",
    "\n",
    "algorithm = ProtoNet(\n",
    "    model=model,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_way=n_way,\n",
    "    n_shot=n_shot,\n",
    "    n_query=n_query,\n",
    "    device='cuda')\n",
    "\n",
    "adaptation_trainer = Generic_adaptation_trainer(\n",
    "    algorithm=algorithm,\n",
    "    aux_objective=None,\n",
    "    outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    outer_optimizer=None, \n",
    "    writer=None,\n",
    "    log_interval=150,\n",
    "    model_type='resnet12'\n",
    ")\n",
    "\n",
    "val_file = os.path.join(dataset_path, 'novel.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=batch_size, n_episodes=n_episodes,\n",
    "    n_way=n_way, n_shot=n_shot, n_query=n_query)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "adaptation_trainer.run(meta_val_loader, meta_val_datamgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-d interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, parameters, split):\n",
    "    image_size = parameters['image_size']\n",
    "    batch_size = 1\n",
    "    n_way = parameters[split]['n_way']\n",
    "    n_shot = parameters[split]['n_shot']\n",
    "    n_query = parameters[split]['n_query']\n",
    "    n_episodes = 100\n",
    "    dataset_path = f\"../data/filelists/{dataset}\"\n",
    "    \n",
    "    algorithm = ProtoNet(\n",
    "        model=model,\n",
    "        inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "        n_way=n_way,\n",
    "        n_shot=n_shot,\n",
    "        n_query=n_query,\n",
    "        device='cuda')\n",
    "\n",
    "    adaptation_trainer = Generic_adaptation_trainer(\n",
    "        algorithm=algorithm,\n",
    "        aux_objective=None,\n",
    "        outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "        outer_optimizer=None, \n",
    "        writer=None,\n",
    "        log_interval=1500,\n",
    "        model_type='resnet12'\n",
    "    )\n",
    "\n",
    "    if split == 'train':\n",
    "        file = os.path.join(dataset_path, 'base.json')\n",
    "    else:\n",
    "        file = os.path.join(dataset_path, 'novel.json')\n",
    "    \n",
    "    meta_datamgr = MetaDataManager(\n",
    "        image_size, batch_size=batch_size, n_episodes=500,\n",
    "        n_way=n_way, n_shot=n_shot, n_query=n_query)\n",
    "    meta_loader = meta_datamgr.get_data_loader(file, support_aug=False, query_aug=False)\n",
    "    return adaptation_trainer.run(meta_loader, meta_datamgr)['test_loss_after']['loss']\n",
    "\n",
    "\n",
    "def moving_average(net1, net2, net, alpha=1):\n",
    "    for param, param1, param2 in zip(net.parameters(), net1.parameters(), net2.parameters()):\n",
    "        param.data = (1.0 - alpha) * param1.data + alpha * param2.data\n",
    "    return net\n",
    "\n",
    "\n",
    "def _check_bn(module, flag):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        flag[0] = True\n",
    "\n",
    "\n",
    "def check_bn(model):\n",
    "    flag = [False]\n",
    "    model.apply(lambda module: _check_bn(module, flag))\n",
    "    return flag[0]\n",
    "\n",
    "\n",
    "def reset_bn(module):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.running_mean = torch.zeros_like(module.running_mean)\n",
    "        module.running_var = torch.ones_like(module.running_var)\n",
    "\n",
    "\n",
    "def _get_momenta(module, momenta):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        momenta[module] = module.momentum\n",
    "\n",
    "\n",
    "def _set_momenta(module, momenta):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.momentum = momenta[module]\n",
    "\n",
    "\n",
    "def bn_update(loader, model):\n",
    "    \"\"\"\n",
    "        BatchNorm buffers update (if any).\n",
    "        Performs 1 epochs to estimate buffers average using train dataset.\n",
    "        :param loader: train dataset loader for buffers average estimation.\n",
    "        :param model: model being update\n",
    "        :return: None\n",
    "    \"\"\"\n",
    "    if not check_bn(model):\n",
    "        return\n",
    "    model.train()\n",
    "    momenta = {}\n",
    "    model.apply(reset_bn)\n",
    "    model.apply(lambda module: _get_momenta(module, momenta))\n",
    "    n = 0\n",
    "    for input, _ in loader:\n",
    "        input = input.cuda()\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        b = input_var.data.size(0)\n",
    "\n",
    "        momentum = b / (n + b)\n",
    "        for module in momenta.keys():\n",
    "            module.momentum = momentum\n",
    "\n",
    "        model(input_var)\n",
    "        n += b\n",
    "\n",
    "    model.apply(lambda module: _set_momenta(module, momenta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(model_0, model_1, model, dataset, parameters, loader, eta=0.05, alpha_st=-0.2, alpha_end=1.2):\n",
    "\n",
    "      \n",
    "    metrics = defaultdict(list)\n",
    "    for alpha in np.arange(alpha_st, alpha_end, eta):\n",
    "        with torch.no_grad():\n",
    "            model = moving_average(model_0, model_1, model, eta)\n",
    "            bn_update(loader, model)\n",
    "            metrics['train'].append(evaluate(model, dataset, parameters, split='train'))\n",
    "            metrics['test'].append(evaluate(model, dataset, parameters, split='test'))\n",
    "            print(\"alpha\",  alpha, metrics['train'][-1], metrics['test'][-1])\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit norm projection is  False\n",
      "loading from ../train_dir/metal_MI_r12_n60_s5_q5_euc/classical_resnet_020.pt\n",
      "Missed 0 keys\n",
      "Unit norm projection is  False\n",
      "loading from ../train_dir/metal_MI_r12_n64_s3_q128_ML/classical_resnet_120.pt\n",
      "Missed 4 keys\n",
      "Unit norm projection is  False\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha -0.2 4.154905759811402 1.6090115864276886\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha -0.15000000000000002 4.154874011039734 1.6090160603523254\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha -0.10000000000000003 4.1548966178894045 1.609009463071823\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha -0.050000000000000044 4.15491074180603 1.609015154838562\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha -5.551115123125783e-17 4.154936699867249 1.6090153985023499\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.04999999999999993 4.154910030364991 1.6090138502120972\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.09999999999999992 4.154912347793579 1.609000334739685\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.1499999999999999 4.154906957626343 1.6090109436511992\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.1999999999999999 4.1549032030105595 1.6090048913955688\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.2499999999999999 4.154940553665162 1.6090224826335906\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.2999999999999999 4.154921274185181 1.6090114572048186\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.3499999999999998 4.1548865566253665 1.6090136134624482\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.39999999999999986 4.154960340499878 1.6090159068107606\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.4499999999999999 4.154918323516846 1.6090256025791168\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.49999999999999983 4.154890657424927 1.6090064499378205\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.5499999999999998 4.154916257858276 1.6090033805370332\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.5999999999999999 4.154942041397095 1.6090258831977844\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.6499999999999999 4.1549083452224735 1.6090105526447296\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.6999999999999997 4.154900533676147 1.6090050618648528\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.7499999999999998 4.154888029098511 1.6090081386566162\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.7999999999999998 4.154931872367859 1.6090170316696166\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.8499999999999999 4.154913875579834 1.6090119092464448\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.8999999999999997 4.1548969354629515 1.6090107219219207\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 0.9499999999999997 4.154908080101013 1.609005981683731\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "alpha 0.9999999999999998 4.154934463500976 1.6090008687973023\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 1.0499999999999998 4.154960312843323 1.6090122039318084\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 1.0999999999999999 4.1548986902236935 1.6090208008289337\n",
      "n_way: 64, n_shot: 5, n_query: 5, batch_sz: 1\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "alpha 1.1499999999999997 4.1549138298034665 1.6090192914009094\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'image_size': 84,\n",
    "    'train': {\n",
    "        'n_way': 64,\n",
    "        'n_shot': 5,\n",
    "        'n_query': 5\n",
    "    },\n",
    "    'test': {\n",
    "        'n_way': 5,\n",
    "        'n_shot': 5,\n",
    "        'n_query': 15 \n",
    "    }\n",
    "}  \n",
    "dataset = 'miniImagenet'\n",
    "\n",
    "dataset_path = f\"../data/filelists/{dataset}\"\n",
    "file = os.path.join(dataset_path, 'base.json')    \n",
    "cl_datamgr = ClassicalDataManager(parameters['image_size'], batch_size=128)\n",
    "loader = cl_datamgr.get_data_loader(file, aug=False)\n",
    "\n",
    "\n",
    "chkpt = '../train_dir/metal_MI_r12_n60_s5_q5_euc/classical_resnet_020.pt'\n",
    "model_fixS = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model_fixS = load_model(model_fixS, chkpt)\n",
    "chkpt = '../train_dir/metal_MI_r12_n64_s3_q128_ML/classical_resnet_120.pt'\n",
    "model_meta = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model_meta = load_model(model_meta, chkpt)\n",
    "model = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "model.cuda()\n",
    "\n",
    "metrics = plot_loss(model_fixS, model_meta, model, 'miniImagenet', parameters, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fca3821f750>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.plot(metrics['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_2.ResNet18(\n",
    "    num_classes=64,  \n",
    "    add_bias=False, \n",
    "    no_fc_layer=False,\n",
    "    classifier_type='linear'\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint = '../train_dir/classical_miniimagenet_dc_bn_with_rfc_var_ortho/classical_resnet_147.pt'\n",
    "print(f\"loading from {checkpoint}\")\n",
    "model_dict = model.state_dict()\n",
    "chkpt_state_dict = torch.load(checkpoint)\n",
    "if 'model' in chkpt_state_dict:\n",
    "    chkpt_state_dict = chkpt_state_dict['model']\n",
    "chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "# remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "for key in chkpt_state_dict_cpy.keys():\n",
    "    if 'module.' in key:\n",
    "        new_key = re.sub('module\\.', '',  key)\n",
    "        chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "model_dict.update(chkpt_state_dict)\n",
    "updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "print(f\"Updated {len(updated_keys)} keys using chkpt\")\n",
    "print(\"Following keys updated :\", \"\\n\".join(sorted(updated_keys)))\n",
    "missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "print(f\"Missed {len(missed_keys)} keys\")\n",
    "print(\"Following keys missed :\", \"\\n\".join(sorted(missed_keys)))\n",
    "model.load_state_dict(model_dict)\n",
    "        \n",
    "        \n",
    "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dc = resnet_2.ResNet18(\n",
    "    num_classes=64,  \n",
    "    no_fc_layer=False,\n",
    "    classifier_type='ortho-classifier'\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint = '../train_dir/classical_miniimagenet_dc_bn_ldim/classical_resnet_137.pt'\n",
    "print(f\"loading from {checkpoint}\")\n",
    "model_dict = model_dc.state_dict()\n",
    "chkpt_state_dict = torch.load(checkpoint)\n",
    "if 'model' in chkpt_state_dict:\n",
    "    chkpt_state_dict = chkpt_state_dict['model']\n",
    "chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "# remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "for key in chkpt_state_dict_cpy.keys():\n",
    "    if 'module.' in key:\n",
    "        new_key = re.sub('module\\.', '',  key)\n",
    "        chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "model_dict.update(chkpt_state_dict)\n",
    "updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "print(f\"Updated {len(updated_keys)} keys using chkpt\")\n",
    "print(\"Following keys updated :\", \"\\n\".join(sorted(updated_keys)))\n",
    "missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "print(f\"Missed {len(missed_keys)} keys\")\n",
    "print(\"Following keys missed :\", \"\\n\".join(sorted(missed_keys)))\n",
    "model_dc.load_state_dict(model_dict)\n",
    "        \n",
    "        \n",
    "model_dc = torch.nn.DataParallel(model_dc, device_ids=range(torch.cuda.device_count()))\n",
    "model_dc.cuda()\n",
    "model_dc.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "train_file = os.path.join(dataset_path, 'base.json')\n",
    "classical_val_datamgr = ClassicalDataManager(image_size, batch_size=16)\n",
    "classical_val_loader = classical_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "classical_train_datamgr = ClassicalDataManager(image_size, batch_size=16)\n",
    "classical_train_loader = classical_val_datamgr.get_data_loader(train_file, aug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, dataloader):\n",
    "    iterator = tqdm(dataloader)\n",
    "    features = defaultdict(list)\n",
    "    for batch in iterator:\n",
    "        batch_x, batch_y = batch\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cpu().numpy()\n",
    "        features_x = model(batch_x, features_only=True)\n",
    "        for y in np.unique(batch_y):\n",
    "            features[y].append(features_x[batch_y==y].detach().cpu().numpy())\n",
    "    for key in features:\n",
    "        features[key] = np.concatenate(features[key], axis=0) \n",
    "        print(f\"Received {features[key].shape} for class {key}\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adhoc anmalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_features = get_features(model, classical_val_loader)\n",
    "train_features = get_features(model, classical_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features_dc = get_features(model_dc, classical_val_loader)\n",
    "train_features_dc = get_features(model_dc, classical_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(64, 80):\n",
    "    A = val_features_dc[x] / np.linalg.norm(val_features_dc[x]+0.00001, axis=1)[:, None]\n",
    "    print(x, (A @ A.T).mean(), (A @ A.T).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, 64):\n",
    "    A = train_features_dc[x] / np.linalg.norm(train_features_dc[x]+0.00001, axis=1)[:, None]\n",
    "    print(x, (A @ A.T).mean(), (A @ A.T).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.cumsum(PCA().fit(val_features_dc[65]).explained_variance_ratio_) < 0.8) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.svd(val_features_dc[69])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = []\n",
    "for x in range(64, 80):\n",
    "    plt.plot(np.cumsum(PCA().fit(val_features_dc[x] / np.linalg.norm(val_features_dc[x], axis=1)[:, None]).explained_variance_ratio_[:10]), label='train', color='blue')\n",
    "    avg.append(sum(np.cumsum(PCA().fit(val_features_dc[x] / np.linalg.norm(val_features_dc[x], axis=1)[:, None]).explained_variance_ratio_) < 0.8) + 1)\n",
    "print(np.mean(avg))\n",
    "# for x in range(0, 64):\n",
    "#     plt.plot(np.cumsum(PCA().fit(train_features_dc[x]).explained_variance_ratio_[:10]), label='train_dc', color='green')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x, PCA().fit(train_features_dc[10]).components_[0] @ model_dc.module.fc.L.weight_v[x].detach().cpu().numpy()) for x in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(pairwise_distances(\n",
    "    PCA().fit(val_features_dc[65]).components_,\n",
    "    PCA().fit(val_features_dc[66]).components_,\n",
    "    metric='cosine'\n",
    ")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(PCA().fit(val_features[71]).explained_variance_ratio_[:30]), label='val')\n",
    "plt.plot(np.cumsum(PCA().fit(train_features[40]).explained_variance_ratio_[:30]), label='train')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking linear seperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = val_features_dc\n",
    "dim = feature_set[list(feature_set.keys())[0]].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset:    \n",
    "    def __init__(self, features):\n",
    "        self.features = np.concatenate([features[x] for x in features], axis=0)\n",
    "        self.target = np.repeat(np.arange(len(features)), features[list(features.keys())[0]].shape[0])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i], self.target[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(feature_set)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "M = torch.nn.Linear(dim, len(feature_set))\n",
    "torch.nn.init.xavier_uniform_(M.weight)\n",
    "M = M.cuda()\n",
    "loss_layer = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(M.parameters(), lr=0.001)\n",
    "# train\n",
    "for epoch in range(1000):\n",
    "    for i, (batch_x, batch_y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.cuda()\n",
    "#         batch_x = batch_x / (torch.norm(batch_x, dim=1, p=2, keepdim=True) + 0.00001)\n",
    "        batch_y = batch_y.cuda()\n",
    "        logits = M(batch_x)\n",
    "        loss = loss_layer(logits, batch_y)\n",
    "        loss.backward()\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"epoch: {epoch} iter : {i} loss : {loss.item()}, accuracy: {accuracy(logits, batch_y) * 100.}\")\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "loss = []\n",
    "for i, (batch_x, batch_y) in enumerate(loader):\n",
    "    batch_x = batch_x.cuda()\n",
    "    batch_x = batch_x / (torch.norm(batch_x, dim=1, p=2, keepdim=True) + 0.00001)\n",
    "    batch_y = batch_y.cuda()\n",
    "    with torch.no_grad():\n",
    "        logits = M(batch_x)\n",
    "        loss.append(loss_layer(logits, batch_y).item())\n",
    "        accu.append(accuracy(logits, batch_y) * 100.)\n",
    "print(np.mean(accu), np.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimensionality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = val_features_dc\n",
    "dim = feature_set[list(feature_set.keys())[0]].shape[1]\n",
    "n_classes = len(feature_set)\n",
    "low_dim = 20\n",
    "label_offset = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone, dim, low_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.backbone.eval()\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, low_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(low_dim, low_dim),\n",
    "            torch.nn.Linear(low_dim, n_classes, bias=False)\n",
    "        )\n",
    "#         torch.nn.init.xavier_normal_(self.mlp.weight)\n",
    "            \n",
    "    def forward(self, x, features_only=False):\n",
    "        if features_only:\n",
    "            return self.mlp[:-1](self.backbone(x, features_only=True).detach()) \n",
    "        return self.mlp(self.backbone(x, features_only=True).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_2.ResNet18(\n",
    "    num_classes=64,  \n",
    "    no_fc_layer=True\n",
    ")\n",
    "\n",
    "checkpoint = '../train_dir/classical_miniimagenet_dc_bn_with_var_ortho_scale_test/classical_resnet_217.pt'\n",
    "print(f\"loading from {checkpoint}\")\n",
    "model_dict = model.state_dict()\n",
    "chkpt_state_dict = torch.load(checkpoint)\n",
    "if 'model' in chkpt_state_dict:\n",
    "    chkpt_state_dict = chkpt_state_dict['model']\n",
    "chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "# remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "for key in chkpt_state_dict_cpy.keys():\n",
    "    if 'module.' in key:\n",
    "        new_key = re.sub('module\\.', '',  key)\n",
    "        chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "model_dict.update(chkpt_state_dict)\n",
    "updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "print(f\"Updated {len(updated_keys)} keys using chkpt\")\n",
    "print(\"Following keys updated :\", \"\\n\".join(sorted(updated_keys)))\n",
    "missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "print(f\"Missed {len(missed_keys)} keys\")\n",
    "print(\"Following keys missed :\", \"\\n\".join(sorted(missed_keys)))\n",
    "model.load_state_dict(model_dict)\n",
    "        \n",
    "projector = Projector(model, dim, low_dim, n_classes)\n",
    "projector = torch.nn.DataParallel(projector, device_ids=range(torch.cuda.device_count()))\n",
    "projector.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "classical_val_datamgr = ClassicalDataManager(image_size, batch_size=32)\n",
    "classical_val_loader = classical_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "loss_layer = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(projector.module.mlp.parameters(), lr=0.001)\n",
    "lambda_epoch = lambda e: 1.0 if e < 50  else 0.1\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda_epoch, last_epoch=-1)\n",
    "    \n",
    "for epoch in range(1000):\n",
    "    avg_loss = []\n",
    "    avg_accu = []\n",
    "    iterator = enumerate(classical_val_loader)\n",
    "    for i, batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        batch_x, batch_y = batch\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "        batch_y = batch_y - label_offset\n",
    "        logits = projector(batch_x)\n",
    "        loss = loss_layer(logits, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss.append(loss.item())\n",
    "        avg_accu.append(accuracy(logits, batch_y) * 100.)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"epoch: {epoch} iter: {i} loss : {np.mean(avg_loss)}, accuracy: {np.mean(avg_accu)}\")\n",
    "        if epoch % 5 == 0:\n",
    "            with open(f\"models/projector_{epoch}.pt\", 'wb') as f:\n",
    "                torch.save(projector.state_dict(), f)\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = val_features_dc[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA() \n",
    "z = pc.fit(A).components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pc.transform(A)) @ z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm = SVM(\n",
    "#     model=model_dc,\n",
    "#     inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "#     n_way=5,\n",
    "#     n_shot=5,\n",
    "#     n_query=15,\n",
    "#     C_reg=1.0,\n",
    "#     device='cuda'\n",
    "# )\n",
    "\n",
    "algorithm = Finetune(\n",
    "    model=model_dc,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_updates=500,\n",
    "    classifier_type='distance-classifier',\n",
    "    final_feat_dim=model_dc.module.final_feat_dim,\n",
    "    n_way=5,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "adaptation_trainer = Generic_adaptation_trainer(\n",
    "    algorithm=algorithm,\n",
    "    aux_objective=None,\n",
    "    outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    outer_optimizer=None, \n",
    "    writer=None,\n",
    "    log_interval=1, grad_clip=0.,\n",
    "    model_type='resnet',\n",
    "    n_aux_objective_steps=0,\n",
    "    label_offset=0)\n",
    "\n",
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=1, n_episodes=50,\n",
    "    n_way=5, n_shot=5, n_query=15)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "adaptation_trainer.run(meta_val_loader, meta_val_datamgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(y_batch, n_way, n_shot, n_query, batch_sz):\n",
    "    # original y_batch: (batch_sz*n_way, n_shot+n_query)\n",
    "    y_batch = y_batch.reshape(batch_sz, n_way, -1)\n",
    "    # batch_sz, n_way, n_shot+n_query\n",
    "\n",
    "    for i in range(y_batch.shape[0]):\n",
    "        uniq_classes = np.unique(y_batch[i, :, :])\n",
    "        conversion_dict = {v:k for k, v in enumerate(uniq_classes)}\n",
    "        # convert labels\n",
    "        for uniq_class in uniq_classes: \n",
    "            y_batch[i, y_batch[i]==uniq_class] = conversion_dict[uniq_class]\n",
    "\n",
    "    shots_y = y_batch[:, :, :n_shot]\n",
    "    query_y = y_batch[:, :, n_shot:]\n",
    "    shots_y = shots_y.reshape(batch_sz, -1)\n",
    "    query_y = query_y.reshape(batch_sz, -1)\n",
    "    return shots_y, query_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=10, n_episodes=50,\n",
    "    n_way=5, n_shot=5, n_query=15)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "it = iter(meta_val_loader)\n",
    "batch_sz=10\n",
    "n_way=5\n",
    "n_shot=5\n",
    "n_query=15\n",
    "x_batch, y_batch = next(it)\n",
    "original_shape = x_batch.shape\n",
    "# (batch_sz*n_way, n_shot+n_query, channels , height , width)\n",
    "x_batch = x_batch.reshape(batch_sz, n_way, *original_shape[-4:])\n",
    "# (batch_sz, n_way, n_shot+n_query, channels , height , width)\n",
    "shots_x = x_batch[:, :, :n_shot, :, :, :]\n",
    "# (batch_sz, n_way, n_shot, channels , height , width)\n",
    "query_x = x_batch[:, :, n_shot:, :, :, :]\n",
    "# (batch_sz, n_way, n_query, channels , height , width)\n",
    "shots_x = shots_x.reshape(batch_sz, -1, *original_shape[-3:])\n",
    "# (batch_sz, n_way*n_shot, channels , height , width)\n",
    "query_x = query_x.reshape(batch_sz, -1, *original_shape[-3:])\n",
    "shots_y, query_y = get_labels(y_batch, n_way, n_shot, n_query, batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "sup_x = shots_x[0]\n",
    "sup_y = shots_y[0]\n",
    "quer_x = query_x[0]\n",
    "quer_y = query_y[0]\n",
    "feat_xs = model_dc(sup_x , features_only=True)\n",
    "feat_xq = model_dc(quer_x , features_only=True)\n",
    "feat_xs = feat_xs / (torch.norm(feat_xs, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "feat_xq = feat_xq / (torch.norm(feat_xq, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "knn_classifier.fit(feat_xs.detach().cpu().numpy(), sup_y.cpu().numpy())\n",
    "sum(knn_classifier.predict(feat_xq.detach().cpu().numpy()) == quer_y.cpu().numpy()) / len(quer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.svd(feat_x)[2].t()[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    sup_x = shots_x[j]\n",
    "    sup_y = shots_y[j]\n",
    "    quer_x = query_x[j]\n",
    "    quer_y = query_y[j]\n",
    "    ll = torch.nn.Linear(512, 16)\n",
    "    ll = ll.cuda()\n",
    "    loss_layer = torch.nn.CrossEntropyLoss()\n",
    "    saved_state_dict = model_dc.state_dict()\n",
    "    opt = torch.optim.Adam([\n",
    "#         {'params': model_dc.parameters(), 'lr': 0.0001},\n",
    "        {'params': ll.parameters(), 'lr': 0.001},\n",
    "    ]) \n",
    "    \n",
    "    sup_x = sup_x.cuda()\n",
    "    sup_y = sup_y.cuda()\n",
    "        \n",
    "    feat_x = model_dc(sup_x , features_only=True)\n",
    "    feat_x = feat_x / (torch.norm(feat_x, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "    feat_x = feat_x.detach()\n",
    "        \n",
    "#     torch.svd(feat_x)[2][]\n",
    "    \n",
    "    for k in range(250):\n",
    "        opt.zero_grad() \n",
    "        loss = loss_layer(ll(feat_x), sup_y) + 0.1 * torch.sum(ll.weight ** 2)\n",
    "        loss.backward()\n",
    "        opt.step()   \n",
    "#     print(f\"loss: {loss.item()}\")\n",
    "    quer_x = quer_x.cuda()\n",
    "    quer_y = quer_y.cuda() \n",
    "    feat_x = model_dc(quer_x , features_only=True)\n",
    "    feat_x = feat_x / (torch.norm(feat_x, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "    quer_logits = ll(feat_x)\n",
    "    model_dc.load_state_dict(saved_state_dict)\n",
    "    print(accuracy(quer_logits, quer_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(72 + 66 + 77 + 65 + 65 + 80 + 70 + 77 + 70 + 61)/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(14/15 + 13/15 + 11/15 + 12/15 + 10/15) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(((np.linalg.svd(S[ys==0])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "# print(np.sum(((np.linalg.svd(S[ys==1])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "# print(np.sum(((np.linalg.svd(S[ys==3])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "# print(np.sum(((np.linalg.svd(S[ys==4])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "np.argmax(np.concatenate([\n",
    "    np.sum(((np.linalg.svd(S[ys==0])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==1])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==2])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==3])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==4])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :]\n",
    "], axis=0).T, axis=1)\n",
    "# print(np.sum((PCA().fit(S[ys==1]).transform(Q[yq==0]))**2, axis=1))\n",
    "# print(np.sum((PCA().fit(S[ys==2]).transform(Q[yq==0]))**2, axis=1))\n",
    "# print(np.sum((PCA().fit(S[ys==3]).transform(Q[yq==0]))**2, axis=1))\n",
    "# print(np.sum((PCA().fit(S[ys==4]).transform(Q[yq==0]))**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_x = shots_x[1]\n",
    "sup_y = shots_y[1]\n",
    "quer_x = query_x[1]\n",
    "quer_y = query_y[1]\n",
    "feat_xs = model_dc(sup_x , features_only=True)\n",
    "feat_xq = model_dc(quer_x , features_only=True)\n",
    "feat_xs = feat_xs / (torch.norm(feat_xs, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "feat_xq = feat_xq / (torch.norm(feat_xq, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "S = feat_xs.detach().cpu().numpy()\n",
    "Q = feat_xq.detach().cpu().numpy()\n",
    "ys = sup_y.cpu().numpy()\n",
    "yq = quer_y.cpu().numpy()\n",
    "np.linalg.svd(np.concatenate([S[ys==0][:1, :], S[ys==1][:1, :], S[ys==2][:1, :], S[ys==3][:1, :], S[ys==4][:1, :]], axis=0))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = PCA(2).fit_transform(feat_x[sup_y==0].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "# arr = PCA(2).fit_transform(feat_x[sup_y==1].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "# arr = PCA(2).fit_transform(feat_x[sup_y==2].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "# arr = PCA(2).fit_transform(feat_x[sup_y==3].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "pca_model = PCA(3)\n",
    "\n",
    "sup_x = shots_x[6]\n",
    "sup_y = shots_y[6]\n",
    "quer_x = query_x[6]\n",
    "quer_y = query_y[6]\n",
    "feat_xs = model_dc(sup_x , features_only=True)\n",
    "feat_xq = model_dc(quer_x , features_only=True)\n",
    "feat_xs = feat_xs / (torch.norm(feat_xs, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "feat_xq = feat_xq / (torch.norm(feat_xq, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "\n",
    "arr = pca_model.fit_transform(feat_xs.detach().cpu().numpy())\n",
    "arr2 = pca_model.transform(feat_xq.detach().cpu().numpy())\n",
    "ys = sup_y.cpu().numpy()\n",
    "yq = quer_y.cpu().numpy()\n",
    "# ax.scatter(arr[ys==0, 0], arr[ys==0, 1], arr[ys==0, 2])\n",
    "ax.scatter(arr2[yq==0, 0], arr2[yq==0, 1], arr2[yq==0, 2])\n",
    "# ax.scatter(arr[ys==1, 0], arr[ys==1, 1], arr[ys==1, 2])\n",
    "ax.scatter(arr2[yq==2, 0], arr2[yq==2, 1], arr2[yq==2, 2])\n",
    "ax.scatter(arr2[yq==3, 0], arr2[yq==3, 1], arr2[yq==3, 2])\n",
    "ax.scatter(arr2[yq==4, 0], arr2[yq==4, 1], arr2[yq==4, 2])\n",
    "ax.scatter(arr2[yq==1, 0], arr2[yq==1, 1], arr2[yq==1, 2])\n",
    "# ax.scatter(arr[ys==1, 0], arr[ys==1, 1], arr[ys==1, 2])\n",
    "# ax.scatter(arr[ys==2, 0], arr[ys==2, 1], arr[ys==2, 2])\n",
    "# ax.scatter(arr[ys==4, 0], arr[ys==4, 1], arr[ys==4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projector.module.scale = 1.0\n",
    "algorithm = SVM(\n",
    "    model=projector,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_way=5,\n",
    "    n_shot=5,\n",
    "    n_query=15,\n",
    "    device='cuda',\n",
    ")\n",
    "\n",
    "\n",
    "adaptation_trainer = Generic_adaptation_trainer(\n",
    "    algorithm=algorithm,\n",
    "    aux_objective=None,\n",
    "    outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    outer_optimizer=None, \n",
    "    writer=None,\n",
    "    log_interval=10, grad_clip=0.,\n",
    "    model_type='resnet',\n",
    "    n_aux_objective_steps=0,\n",
    "    label_offset=0)\n",
    "\n",
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=5, n_episodes=50,\n",
    "    n_way=5, n_shot=5, n_query=15)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "adaptation_trainer.run(meta_val_loader, meta_val_datamgr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
