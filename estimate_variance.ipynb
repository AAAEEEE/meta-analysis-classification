{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm \n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(\"always\", ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maml.datasets.miniimagenet import MiniimagenetMetaDataset\n",
    "from maml.models.gated_conv_net_original import ImpRegConvModel\n",
    "from maml.models.conv_embedding_model import RegConvEmbeddingModel\n",
    "from maml.logistic_regression_utils import logistic_regression_grad_with_respect_to_w, logistic_regression_hessian_pieces_with_respect_to_w, logistic_regression_hessian_with_respect_to_w, logistic_regression_mixed_derivatives_with_respect_to_w_then_to_X\n",
    "from maml.logistic_regression_utils import logistic_regression_mixed_derivatives_with_respect_to_w_then_to_X_left_multiply\n",
    "from maml.algorithm import MetaOptnet, ProtoNet, ImpRMAML_inner_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_indices(array, n_classes):\n",
    "    for c in range(n_classes):\n",
    "        np.argwhere(array==c)\n",
    "def compute_variance(estimators, n_classes):\n",
    "    estimators = torch.cat(estimators, dim=0).numpy()\n",
    "    assert estimators.shape[1] == n_classes\n",
    "    assert len(estimators.shape) == 3\n",
    "    _explained_variance_ratio = []\n",
    "    for i in range(n_classes):\n",
    "        est = estimators[:, i, :]\n",
    "        est = est - est.mean(0)\n",
    "        svd = TruncatedSVD(n_components=min(est.shape), n_iter=10, random_state=42)\n",
    "        S = svd.fit(est.T @ est)\n",
    "#         print(f\"class: {i+1} exp. variance: \", S.explained_variance_ratio_)\n",
    "#         print(f\"class: {i+1} svd values : \", S.singular_values_)\n",
    "        _explained_variance_ratio.append(S.explained_variance_ratio_)\n",
    "    return np.stack(_explained_variance_ratio, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_stat = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM 5w5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniImagenet val\n",
      "add_bias to output features :  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Modulation\n",
      "tensor([17.7936, 15.9337, 17.9058, 16.8586, 16.6797, 15.8675, 17.2483, 16.4833,\n",
      "        16.4663, 15.0004, 16.8906, 18.0275, 16.0311, 17.0132, 17.0913, 17.4745,\n",
      "        17.3989, 17.4011, 17.1517, 16.9257, 17.6283, 16.0403, 17.2479, 16.6842,\n",
      "        17.1293], device='cuda:1', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:15<00:00,  7.79it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.71it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.74it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.87it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.71it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.79it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.77it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.62it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.67it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.60it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.66it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.75it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.68it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.59it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.66it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.58it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.65it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.74it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.68it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.88it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.87it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.65it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.89it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.75it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.73it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.76it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.79it/s]\n",
      "100%|██████████| 120/120 [00:14<00:00,  8.55it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.62it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.63it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.69it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.72it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.74it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.66it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.89it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.74it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.81it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.81it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.85it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.78it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.76it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.84it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  9.00it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.95it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.88it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.78it/s]\n",
      "100%|██████████| 120/120 [00:14<00:00,  8.53it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.76it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.65it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.77it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.64it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.80it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.64it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.77it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.57it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.86it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.78it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.77it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.72it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.69it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.84it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.86it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.81it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.80it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.76it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.90it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.82it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.79it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.80it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.66it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.63it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.66it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.76it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.82it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.75it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.70it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.89it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.76it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.58it/s]\n",
      "100%|██████████| 120/120 [00:14<00:00,  8.55it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.78it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.68it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.65it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.61it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.69it/s]\n",
      "100%|██████████| 120/120 [00:14<00:00,  8.49it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.68it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.59it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.69it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.65it/s]\n",
      "100%|██████████| 120/120 [00:14<00:00,  8.54it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.71it/s]\n",
      "100%|██████████| 120/120 [00:13<00:00,  8.80it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_name = 'SVM 5w5s'\n",
    "chkpt = './inner_solvers/minim_5w5s_SVM/maml_impregconv_20000.pt'\n",
    "torch.cuda.set_device(1)\n",
    "n_runs = 10\n",
    "n_way=5\n",
    "n_shot=5\n",
    "\n",
    "# dataset\n",
    "dataset = MiniimagenetMetaDataset(\n",
    "    root='data',\n",
    "    img_side_len=84,\n",
    "    num_classes_per_batch=n_way,\n",
    "    num_samples_per_class=600, # num train samples per class\n",
    "    num_total_batches=10,\n",
    "    num_val_samples=0, # num test samples per class\n",
    "    meta_batch_size=1,\n",
    "    split='val', # meta train/val/test\n",
    "    num_workers=4,\n",
    "    device='cuda')\n",
    "num_channels = 64\n",
    "\n",
    "\n",
    "# model \n",
    "model = ImpRegConvModel(\n",
    "        input_channels=dataset.input_size[0],\n",
    "        output_size=dataset.output_size,\n",
    "        num_channels=64,\n",
    "        img_side_len=dataset.input_size[1],\n",
    "        use_max_pool=False, # currently not used\n",
    "        verbose=False,\n",
    "        use_group_norm=True,\n",
    "        retain_activation=True,\n",
    "        add_bias=False)\n",
    "state_dict = torch.load(chkpt)\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.to('cuda')\n",
    "\n",
    "\n",
    "# algorithm\n",
    "algorithm = MetaOptnet(\n",
    "    model=model,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_way=n_way,\n",
    "    n_shot_train=n_shot,\n",
    "    n_shot_val=n_shot,\n",
    "    device='cuda')\n",
    "\n",
    "\n",
    "# start variance computation\n",
    "explained_variance_ratio = []\n",
    "for train_task_batch, _ in iter(dataset):\n",
    "\n",
    "    train_task = train_task_batch[0]\n",
    "    n_samples = train_task.x.shape[0]\n",
    "    train_task_batch_x = torch.stack([task.x for task in train_task_batch], dim=0)\n",
    "    train_task_batch_y = torch.stack([task.y for task in train_task_batch], dim=0)\n",
    "    n_samples_per_class = n_samples // n_way\n",
    "    n_tasks = (n_samples_per_class // n_shot)\n",
    "    estimators = []\n",
    "        \n",
    "    for _ in range(n_runs):\n",
    "        train_task_batch_x_shuffled = []\n",
    "        for i in range(n_way):\n",
    "            random_indices = np.random.permutation(n_samples_per_class)\n",
    "            train_task_batch_x_shuffled.append(train_task_batch_x[:, random_indices + i*n_samples_per_class])\n",
    "        train_task_batch_x = torch.cat(train_task_batch_x_shuffled, dim=1)\n",
    "        for i in tqdm(range(0, n_tasks)):\n",
    "            indices = np.array(\n",
    "                [[n_samples_per_class*j + n_shot*i + k for k in range(n_shot)] for j in range(n_way)]\n",
    "            ).reshape(-1).tolist()\n",
    "            samples_x = train_task_batch_x[:,indices]\n",
    "            samples_y = train_task_batch_y[:,indices]\n",
    "            assert len(set(samples_y.view(-1).cpu().numpy())) == n_way\n",
    "        #         print(samples_x.shape, samples_y.shape, len(set(samples_y.view(-1))))\n",
    "            estimators.append(algorithm.inner_loop_adapt(\n",
    "                support=samples_x, \n",
    "                support_labels=samples_y, \n",
    "                query=samples_x,\n",
    "                return_estimator=True\n",
    "            ).detach().cpu())\n",
    "    explained_variance_ratio.append(compute_variance(estimators, n_classes=n_way))\n",
    "\n",
    "variance_stat[exp_name] = np.concatenate(explained_variance_ratio, axis=0).mean(0)\n",
    "plt.plot(variance_stat[exp_name])\n",
    "plt.xticks(np.arange(0, variance_stat[exp_name].shape[-1], 50), size=8)\n",
    "plt.title(exp_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM 5w1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniImagenet val\n",
      "add_bias to output features :  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/600 [00:00<01:15,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Modulation\n",
      "tensor([17.0096, 15.3125, 17.6652, 16.3355, 16.0569], device='cuda:1',\n",
      "       grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:41<00:00, 14.58it/s]\n",
      "100%|██████████| 600/600 [00:41<00:00, 14.57it/s]\n",
      "100%|██████████| 600/600 [00:39<00:00, 15.35it/s]\n",
      "100%|██████████| 600/600 [00:37<00:00, 15.82it/s]\n",
      "100%|██████████| 600/600 [00:38<00:00, 15.40it/s]\n",
      "100%|██████████| 600/600 [00:39<00:00, 15.25it/s]\n",
      "100%|██████████| 600/600 [00:39<00:00, 15.30it/s]\n",
      "100%|██████████| 600/600 [00:39<00:00, 15.30it/s]\n",
      " 77%|███████▋  | 462/600 [00:29<00:08, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------\n",
      "qpth warning: Returning an inaccurate and potentially incorrect solution.\n",
      "\n",
      "Some residual is large.\n",
      "Your problem may be infeasible or difficult.\n",
      "\n",
      "You can try using the CVXPY solver to see if your problem is feasible\n",
      "and you can use the verbose option to check the convergence status of\n",
      "our solver while increasing the number of iterations.\n",
      "\n",
      "Advanced users:\n",
      "You can also try to enable iterative refinement in the solver:\n",
      "https://github.com/locuslab/qpth/issues/6\n",
      "--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:38<00:00, 15.55it/s]\n",
      "100%|██████████| 600/600 [00:38<00:00, 15.54it/s]\n"
     ]
    }
   ],
   "source": [
    "exp_name = 'SVM 5w1s'\n",
    "chkpt = './inner_solvers/minim_5w1s_SVM/maml_impregconv_22000.pt'\n",
    "torch.cuda.set_device(1)\n",
    "n_runs = 2\n",
    "n_way=5\n",
    "n_shot=1\n",
    "\n",
    "# dataset\n",
    "dataset = MiniimagenetMetaDataset(\n",
    "    root='data',\n",
    "    img_side_len=84,\n",
    "    num_classes_per_batch=n_way,\n",
    "    num_samples_per_class=600, # num train samples per class\n",
    "    num_total_batches=10,\n",
    "    num_val_samples=0, # num test samples per class\n",
    "    meta_batch_size=1,\n",
    "    split='val', # meta train/val/test\n",
    "    num_workers=4,\n",
    "    device='cuda')\n",
    "num_channels = 64\n",
    "\n",
    "\n",
    "# model \n",
    "model = ImpRegConvModel(\n",
    "        input_channels=dataset.input_size[0],\n",
    "        output_size=dataset.output_size,\n",
    "        num_channels=64,\n",
    "        img_side_len=dataset.input_size[1],\n",
    "        use_max_pool=False, # currently not used\n",
    "        verbose=False,\n",
    "        use_group_norm=True,\n",
    "        retain_activation=True,\n",
    "        add_bias=False)\n",
    "state_dict = torch.load(chkpt)\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.to('cuda')\n",
    "\n",
    "\n",
    "# algorithm\n",
    "algorithm = MetaOptnet(\n",
    "    model=model,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_way=n_way,\n",
    "    n_shot_train=n_shot,\n",
    "    n_shot_val=n_shot,\n",
    "    device='cuda')\n",
    "\n",
    "\n",
    "# start variance computation\n",
    "explained_variance_ratio = []\n",
    "for train_task_batch, _ in iter(dataset):\n",
    "\n",
    "    train_task = train_task_batch[0]\n",
    "    n_samples = train_task.x.shape[0]\n",
    "    train_task_batch_x = torch.stack([task.x for task in train_task_batch], dim=0)\n",
    "    train_task_batch_y = torch.stack([task.y for task in train_task_batch], dim=0)\n",
    "    n_samples_per_class = n_samples // n_way\n",
    "    n_tasks = (n_samples_per_class // n_shot)\n",
    "    estimators = []\n",
    "        \n",
    "    for _ in range(n_runs):\n",
    "        train_task_batch_x_shuffled = []\n",
    "        for i in range(n_way):\n",
    "            random_indices = np.random.permutation(n_samples_per_class)\n",
    "            train_task_batch_x_shuffled.append(train_task_batch_x[:, random_indices + i*n_samples_per_class])\n",
    "        train_task_batch_x = torch.cat(train_task_batch_x_shuffled, dim=1)\n",
    "        for i in tqdm(range(0, n_tasks)):\n",
    "            indices = np.array(\n",
    "                [[n_samples_per_class*j + n_shot*i + k for k in range(n_shot)] for j in range(n_way)]\n",
    "            ).reshape(-1).tolist()\n",
    "            samples_x = train_task_batch_x[:,indices]\n",
    "            samples_y = train_task_batch_y[:,indices]\n",
    "            assert len(set(samples_y.view(-1).cpu().numpy())) == n_way\n",
    "        #         print(samples_x.shape, samples_y.shape, len(set(samples_y.view(-1))))\n",
    "            estimators.append(algorithm.inner_loop_adapt(\n",
    "                support=samples_x, \n",
    "                support_labels=samples_y, \n",
    "                query=samples_x,\n",
    "                return_estimator=True\n",
    "            ).detach().cpu())\n",
    "    explained_variance_ratio.append(compute_variance(estimators, n_classes=n_way))\n",
    "\n",
    "variance_stat[exp_name] = np.concatenate(explained_variance_ratio, axis=0).mean(0)\n",
    "plt.plot(variance_stat[exp_name])\n",
    "plt.xticks(np.arange(0, variance_stat[exp_name].shape[-1], 50), size=8)\n",
    "plt.title(exp_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
