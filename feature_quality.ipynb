{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm \n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"always\", ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maml.datasets.miniimagenet import MiniimagenetMetaDataset\n",
    "from maml.models.gated_conv_net_original import ImpRegConvModel\n",
    "from maml.models.conv_embedding_model import RegConvEmbeddingModel\n",
    "from maml.logistic_regression_utils import logistic_regression_grad_with_respect_to_w, logistic_regression_hessian_pieces_with_respect_to_w, logistic_regression_hessian_with_respect_to_w, logistic_regression_mixed_derivatives_with_respect_to_w_then_to_X\n",
    "from maml.logistic_regression_utils import logistic_regression_mixed_derivatives_with_respect_to_w_then_to_X_left_multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniImagenet val\n"
     ]
    }
   ],
   "source": [
    "num_channels = 64\n",
    "dataset = MiniimagenetMetaDataset(\n",
    "    root='data',\n",
    "    img_side_len=84,\n",
    "    num_classes_per_batch=16,\n",
    "    num_samples_per_class=600, # num train samples per class\n",
    "    num_total_batches=1,\n",
    "    num_val_samples=0, # num test samples per class\n",
    "    meta_batch_size=1,\n",
    "    split='train', # meta train/val/test\n",
    "    num_workers=4,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImpRegConvModel(\n",
       "  (features): Sequential(\n",
       "    (layer1_conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (layer1_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer1_lrelu): LeakyReLU(negative_slope=0.1)\n",
       "    (layer1_max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer2_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (layer2_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer2_lrelu): LeakyReLU(negative_slope=0.1)\n",
       "    (layer2_max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer3_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (layer3_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer3_lrelu): LeakyReLU(negative_slope=0.1)\n",
       "    (layer3_max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer4_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (layer4_norm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer4_max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImpRegConvModel(\n",
    "        input_channels=dataset.input_size[0],\n",
    "        output_size=dataset.output_size,\n",
    "        num_channels=num_channels,\n",
    "        img_side_len=dataset.input_size[1],\n",
    "        use_max_pool=False, # currently not used\n",
    "        verbose=False,\n",
    "        use_group_norm=True,\n",
    "        retain_activation=False)\n",
    "state_dict = torch.load('./train_dir/impregmaml_minim_5w1s_sans_modulation_10_groupnorm/maml_impregconv_52000.pt')\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task_batch, test_task_batch = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task = train_task_batch[0]\n",
    "images = train_task.x.cpu().numpy().transpose(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 600,\n",
       "         7: 600,\n",
       "         9: 600,\n",
       "         12: 600,\n",
       "         0: 600,\n",
       "         1: 600,\n",
       "         6: 600,\n",
       "         5: 600,\n",
       "         8: 600,\n",
       "         11: 600,\n",
       "         15: 600,\n",
       "         10: 600,\n",
       "         13: 600,\n",
       "         4: 600,\n",
       "         14: 600,\n",
       "         2: 600})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert train_task.x.size(0) == len(train_task.y)\n",
    "Counter(train_task.y.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 18/96 [00:00<00:43,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Modulation\n",
      "tensor([320.9669, 306.1135, 309.2906, 315.7489, 319.2601, 374.0381, 294.7958,\n",
      "        308.0747, 352.2834, 332.7489, 353.4807, 306.4835, 304.0098, 322.7579,\n",
      "        353.4281, 323.0651, 315.7542, 311.6960, 322.7111, 319.1454, 384.0452,\n",
      "        323.6081, 348.5122, 350.9153, 326.7862, 366.6815, 370.7954, 317.5385,\n",
      "        361.9706, 305.5706, 375.3707, 354.7528, 321.2337, 341.3530, 346.0609,\n",
      "        314.1640, 305.9853, 307.0463, 324.1154, 363.3754, 331.4963, 323.4962,\n",
      "        318.1687, 300.4783, 334.7975, 318.1122, 313.7548, 312.7085, 348.3203,\n",
      "        323.2894, 292.4219, 288.0349, 368.3343, 348.8164, 338.6063, 303.9785,\n",
      "        347.2462, 325.0019, 355.7615, 368.3315, 350.5046, 311.4275, 341.8011,\n",
      "        377.8944, 345.1176, 327.3841, 345.5174, 322.8875, 353.0949, 320.6765,\n",
      "        370.5136, 353.2720, 307.4763, 305.5596, 349.3232, 350.5654, 382.0580,\n",
      "        337.1615, 345.2189, 359.6410, 364.0529, 305.2354, 367.1454, 336.4810,\n",
      "        310.9576, 350.8200, 364.6143, 333.1251, 307.1074, 328.2455, 265.0065,\n",
      "        334.1328, 349.3366, 310.1122, 344.0990, 320.8509, 338.9811, 345.6075,\n",
      "        333.9138, 362.1196], device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:01<00:00, 69.81it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in tqdm(range(0, len(train_task.x), 100)):\n",
    "    X.append(model(train_task.x[i:(i+100),:,:,:], modulation=None).detach().cpu().numpy())\n",
    "    y.append(train_task.y[i:(i+100)].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(X, axis=0)\n",
    "y = np.concatenate(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 1601)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lambda = 0.001\n",
    "with warnings.catch_warnings(record=True) as wn:\n",
    "    lr_model = LogisticRegression(solver='lbfgs', penalty='l2', \n",
    "        C=1/l2_lambda, # now use _l2_lambda instead of 2 * _l2_lambda\n",
    "        tol=1e-6, max_iter=1000,\n",
    "        multi_class='multinomial', fit_intercept=False)\n",
    "    lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 94.65625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy : {np.sum(lr_model.predict(X) == y)*100./len(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features \n",
    "X = model(train_task_batch[0].x, modulation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_task_batch, test_task_batch in iter(dataset):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task = train_task_batch[0]\n",
    "test_task = test_task_batch[0]\n",
    "print(train_task.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = test_task.x.cpu().numpy().transpose(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[595])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImpRegConvModel(\n",
    "        input_channels=dataset.input_size[0],\n",
    "        output_size=dataset.output_size,\n",
    "        num_channels=num_channels,\n",
    "        img_side_len=dataset.input_size[1],\n",
    "        use_max_pool=False, # currently not used\n",
    "        verbose=False,\n",
    "        use_group_norm=True,\n",
    "        retain_activation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./train_dir/impregmaml_minim_5w1s_sans_modulation_10_groupnorm/maml_impregconv_52000.pt')\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for a in model.features.named_children():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model(train_task.x, modulation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = []\n",
    "# with torch.no_grad():\n",
    "#     for i in range(192):\n",
    "#         result.append(model(train_task.x[i * 50: (i+1) * 50], modulation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_task.x.shape)\n",
    "# X = torch.cat(result, dim=0)\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.detach().cpu().numpy()\n",
    "y = (train_task.y).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lambda = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(record=True) as wn:\n",
    "    lr_model = LogisticRegression(solver='lbfgs', penalty='l2', \n",
    "        C=1/l2_lambda, # now use _l2_lambda instead of 2 * _l2_lambda\n",
    "        tol=1e-6, max_iter=1000,\n",
    "        multi_class='multinomial', fit_intercept=False)\n",
    "    lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(lr_model.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        indices.append(595 * i + j)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = model(test_task.x[indices], modulation=None)\n",
    "X_test = X_test.detach().cpu().numpy()\n",
    "y_test = (test_task.y[indices]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_result = []\n",
    "# test_result.append(model(test_task.x[0:5], modulation=None))\n",
    "# test_result.append(model(test_task.x[595:600], modulation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = model(test_task.x, modulation=None)\n",
    "# X_test = X_test.detach().cpu().numpy()\n",
    "# y_test = (test_task.y).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_task.x.shape)\n",
    "X_test = torch.cat(test_result, dim=0)\n",
    "print(X_test.shape)\n",
    "X_test = X_test.detach().cpu().numpy()\n",
    "y_test = (test_task.y).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(lr_model.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from maml.datasets.task import plot_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_task.x.cpu().numpy().transpose(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1207])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1801])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[2400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[2401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
